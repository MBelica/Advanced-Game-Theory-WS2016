\documentclass[12pt]{extreport} % Schriftgröße: 8pt, 9pt, 10pt, 11pt, 12pt, 14pt, 17pt oder 20pt

% Language Setup (Deutsch)
\usepackage[utf8]{inputenc} 
\usepackage[english]{babel}

%% Packages
\usepackage{scrextend}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage[inline]{enumitem}
\usepackage{changes}
\usepackage{chngcntr}
\usepackage{cmap}
\usepackage{color}
\usepackage{csquotes}
\usepackage{float}
\usepackage{hyperref}
\usepackage{footnote}
\usepackage{lmodern}
\usepackage{makeidx}
\usepackage{mathtools} 
\usepackage{xpatch}
\usepackage{pgfplots}
\usepackage{stmaryrd}
\usepackage{pbox}
\usepackage{apptools}
\usepackage{booktabs}
\usepackage{dsfont}
\usepackage{subcaption}
	\expandafter\def\csname ver@subfig.sty\endcsname{}
\usepackage{graphicx}
\usepackage{mathrsfs}
\usepackage[square,numbers]{natbib}
\usepackage{nicefrac}
\usepackage{pgf}
\usepackage{pgfplots}
\usepackage{tikz}
\usepackage{tocloft}
\usepackage{url}
\usepackage{xpatch}
\usepackage{microtype}
\usepackage{pgfplots}
\usepackage{minibox}
\usepackage{xcolor}
\usepackage{sgame}  % Game theory packages
\usepackage{subfig} % Manipulation and reference of small or sub figures and tables

\makesavenoteenv{tabular}
\usepgfplotslibrary{fillbetween}
\usetikzlibrary{patterns}
\usetikzlibrary{decorations.markings}
\usetikzlibrary{calc, intersections}
\usetikzlibrary{trees, calc} % For extensive form games
\pgfplotsset{compat=1.7}
\usetikzlibrary{calc}	
\usetikzlibrary{matrix}	

\usepgfplotslibrary{fillbetween}
\usetikzlibrary{patterns}
\usetikzlibrary{decorations.markings}
\usetikzlibrary{calc, intersections}
\usetikzlibrary{trees, calc} % For extensive form games
\pgfplotsset{compat=1.7}
\usetikzlibrary{calc}	
\usetikzlibrary{matrix}	

% Options
\makeatletter%%  
  % Linkfarbe, {0,0.35,0.35} für Türkis, {0,0,0} für Schwarz 
  \definecolor{linkcolor}{rgb}{0,0.35,0.35}
  % Zeilenabstand für bessere Leserlichkeit
  \def\mystretch{1.75} 
  % Publisher definieren
  \newcommand\publishers[1]{\newcommand\@publishers{#1}} 
  % Enumerate im 1. Level: \alph für a), b), \dotsc
  \renewcommand{\labelenumi}{\alph{enumi})} 
  % Enumerate im 2. Level: \roman für (i), (ii), \dotsc
  \renewcommand{\labelenumii}{(\roman{enumii})}
  % Zeileneinrückung am Anfang des Absatzes
  \setlength{\parindent}{0pt} 
  % Verweise auf Enumerate, z.B.: 3.2 a)
  \setlist[enumerate,1]{ref={\thesatz ~ \alph*)}}
  % Für das Proof-Environment: 'Beweis:' anstatt 'Beweis.'
  \xpatchcmd{\proof}{\@addpunct{.}}{\@addpunct{:}}{}{} 
  % Nummerierung der Bilder, z.B.: Abbildung 4.1
  \@ifundefined{thechapter}{}{\def\thefigure{\thechapter.\arabic{figure}}} 
\makeatother%

% Meta Setup (Für Titelblatt und Metadaten im PDF)
\title{Advanced Game Theory}
\author{Prof. Dr. Clemens Puppe}
\date{Vorlesungsmitschrieb (gekürzt) ~\vspace{0.2cm} \\ Wintersemester 2016/17}
\publishers{Karlsruher Institut für Technologie}

%% Math. Definitions
\newcommand{\C}{\mathbb{C}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Z}{\mathbb{Z}}

%% Theorems (unnamedtheorem = Theorem ohne Namen)
\newtheoremstyle{named}{}{}{\normalfont}{}{\bfseries}{:}{0.25em}{#2 \thmnote{#3}}
\newtheoremstyle{itshape}{}{}{\itshape}{}{\bfseries}{:}{ }{}
\newtheoremstyle{normal}{}{}{\normalfont}{}{\bfseries}{:}{ }{}
\renewcommand*{\qed}{\hfill\ensuremath{\square}}

\theoremstyle{named}
\newtheorem{unnamedtheorem}{Theorem} \counterwithin{unnamedtheorem}{chapter}
\newtheorem*{unnamedtheorem*}{Theorem} 

\theoremstyle{itshape}
\newtheorem{theorem}[unnamedtheorem]{Theorem}	
\newtheorem{satz}[unnamedtheorem]{Satz}	
\newtheorem*{definition}{Definition}

\theoremstyle{normal}
\newtheorem{beispiel}[unnamedtheorem]{Beispiel}
\newtheorem{example}[unnamedtheorem]{Example}
\newtheorem{folgerung}[unnamedtheorem]{Folgerung}
\newtheorem{hilfssatz}[unnamedtheorem]{Hilfssatz}
\newtheorem{lemma}[unnamedtheorem]{Lemma}
\newtheorem{proposition}[unnamedtheorem]{Proposition}
\newtheorem{anwendung}[unnamedtheorem]{Anwendung}
\newtheorem{anwendungen}[unnamedtheorem]{Anwendungen}
\newtheorem*{beispiel*}{Beispiel}
\newtheorem*{example*}{Example}
\newtheorem*{beispiele}{Beispiele}
\newtheorem*{examples}{Examples}
\newtheorem*{bemerkung}{Bemerkung} 
\newtheorem*{comment*}{Comment} 
\newtheorem*{bemerkungen}{Bemerkungen}
\newtheorem*{bezeichnung}{Bezeichnung}
\newtheorem*{eigenschaften}{Eigenschaften}
\newtheorem*{erinnerung}{Erinnerung}
\newtheorem*{folgerung*}{Folgerung}
\newtheorem*{folgerungen}{Folgerungen}
\newtheorem*{hilfssatz*}{Hilfssatz}
\newtheorem*{regeln}{Regeln}
\newtheorem*{schreibweise}{Schreibweise}
\newtheorem*{schreibweisen}{Schreibweisen}
\newtheorem*{uebung}{übung}
\newtheorem*{vereinbarung}{Vereinbarung}

%% Template
\makeatletter%
\DeclareUnicodeCharacter{00A0}{ } \pgfplotsset{compat=1.7} \hypersetup{colorlinks,breaklinks, urlcolor=linkcolor, linkcolor=linkcolor, pdftitle=\@title, pdfauthor=\@author, pdfsubject=\@title, pdfcreator=\@publishers}\DeclareOption*{\PassOptionsToClass{\CurrentOption}{report}} \ProcessOptions \def\baselinestretch{\mystretch} \setlength{\oddsidemargin}{0.125in} \setlength{\evensidemargin}{0.125in} \setlength{\topmargin}{0.5in} \setlength{\textwidth}{6.25in} \setlength{\textheight}{8in} \addtolength{\topmargin}{-\headheight} \addtolength{\topmargin}{-\headsep} \def\pulldownheader{ \addtolength{\topmargin}{\headheight} \addtolength{\topmargin}{\headsep} \addtolength{\textheight}{-\headheight} \addtolength{\textheight}{-\headsep} } \def\pullupfooter{ \addtolength{\textheight}{-\footskip} } \def\ps@headings{\let\@mkboth\markboth \def\@oddfoot{} \def\@evenfoot{} \def\@oddhead{\hbox {}\sl \rightmark \hfil \rm\thepage} \def\chaptermark##1{\markright {\uppercase{\ifnum \c@secnumdepth >\m@ne \@chapapp\ \thechapter. \ \fi ##1}}} \pulldownheader } \def\ps@myheadings{\let\@mkboth\@gobbletwo \def\@oddfoot{} \def\@evenfoot{} \def\sectionmark##1{} \def\subsectionmark##1{}  \def\@evenhead{\rm \thepage\hfil\sl\leftmark\hbox {}} \def\@oddhead{\hbox{}\sl\rightmark \hfil \rm\thepage} \pulldownheader }	\def\chapter{\cleardoublepage  \thispagestyle{plain} \global\@topnum\z@ \@afterindentfalse \secdef\@chapter\@schapter} \def\@makeschapterhead#1{ {\parindent \z@ \raggedright \normalfont \interlinepenalty\@M \Huge \bfseries  #1\par\nobreak \vskip 40\p@ }} \newcommand{\indexsection}{chapter} \patchcmd{\@makechapterhead}{\vspace*{50\p@}}{}{}{}
	% Titlepage
	\def\maketitle{ \begin{titlepage} 
			~\vspace{3cm} 
		\begin{center} {\Huge \@title} \end{center} 
	 		\vspace*{1cm} 
	 	\begin{center} {\large \@author} \end{center} 
	 	\begin{center} \@date \end{center} 
	 		\vspace*{7cm} 
	 	\begin{center} \@publishers \end{center} 
	 		\vfill 
	\end{titlepage} }
\makeatother%

% Indexdatei erstellen
\makeindex 

\begin{document}

\pagenumbering{Alph}
\begin{titlepage}
	\maketitle
	\thispagestyle{empty}
\end{titlepage}
\pagenumbering{arabic}
	
% Inhaltsverzeichnis
\tableofcontents
\thispagestyle{empty} 
  
% Skript - Anfang 
\chapter{Noncooperative Games}

\section{Basic Elements of Noncooperative Games}


\begin{definition}
	A \textbf{game} is a formal representation of a situation in which a number of individuals interact in a setting of strategic interdependence.
	
	\begin{itemize}
		\item The players: Who is involved?
		\item The rules: Who moves when? What do they know when they move? What can they do?
		\item The outcomes: For each possible set of actions by the players, what is the outcome of the game?
		\item The payoffs: What are the players' preferences over the possible outcomes?
	\end{itemize} 
\end{definition}

\begin{definition}[Information] ~\
	\begin{enumerate}
		\item \textbf{Information Set:} A player doesn't know which of the nodes in the information set she is actually at. Therefore, at any decision node in a player's information set, there must be the same possible actions.
		\item \textbf{Perfect Information:} A game is said to be of perfect information if each information set contains a single decision node. Otherwise, it is a game of \textbf{imperfect information}.
	\end{enumerate}
\end{definition} 

\begin{definition}[Extensive Form Game] ~\
	A game in \textbf{extensive form} consists of:
	\begin{enumerate}[label=(\roman*\upshape)]
		\item A finite set of nodes $\mathcal{X}$, a finite set of possible actions $\mathcal{A}$, and a finite set of players $\{1, \dotsc, l\}$.
		\item A funktion $p \colon \mathcal{X} \Rightarrow \{ \mathcal{X} \cup \emptyset \}$ specifying a single immediate predecessor of each node $x$; $p(x) \in \mathcal{X}$ expect for one element $x_{0}$, the \textbf{initial node}. The immediate \textbf{successor node} of $x$ are $s(x) = p^{-1}(x)$. ~\\
			To have a tree structure, a predecessor can never be a successor and vice versa. The set of \textbf{terminal nodes} $T = \{ x \in \mathcal{X} \colon s(x) = \emptyset \}$. All other nodes $X \setminus T$ are \textbf{decision nodes}.
		\item A function $\alpha \colon \mathcal{X} \setminus \{ x_{0} \} \Rightarrow \mathcal{A}$ giving the action that leads to any non-initial node $x$ from its immediate predecessor $p(x)$ with $x', x'' \in s(x); x' \neq x'' \Rightarrow \alpha(x') \neq \alpha(x'')$. The set of choices at decision node $x$ is $c(x) = \{ a \in \mathcal{A} \colon a = \alpha(x') \text{ for some } x' \in s(x) \}$.
		\item A collection of information sets $\mathcal{H}$, and a function $H \colon \mathcal{X} \Rightarrow \mathcal{H}$ assigning each decision node $x$ to an information set $H(x) \in \mathcal{H}$ with $c(x) = c(x')$ if H(x) = $H(x')$. ~\\
			The choices available at information set $H$ can be written as
			$$ C(H) = \{ a \in \mathcal{A} \colon a \in c(x) \text{ for } x \in H \}. $$
		\item A function $\iota \colon \mathcal{H} \Rightarrow \{ 0, 1, \dotsc, l \}$ assigning a player to each information set ($i = 0$ 'nature'). ~\\
			The collection of player i's information set is denoted by
			$$ \mathcal{H}_i = \{ H \in \mathcal{H} \colon i = \iota(H) \}. $$
		\item A function $\rho \colon \mathcal{H}_0 \times \mathcal{A} \Rightarrow [0,1]$ assigning a probability to each action of nature with $\rho(H,a) = 0$ if $a \notin C(H)$ und $\sum_{a \in C(H)} \rho(H, a) = 1$ for all $H \in \mathcal{H}_{0}$.
		\item A collection of payoff function $u = \{ u_1(\cdot), \dotsc, u_l(\cdot) \}$, where $u_i \colon T \Rightarrow \R$.
	\end{enumerate}
	\textbf{A game in extensive form:} $\Gamma_E = \{ \mathcal{X}, \mathcal{A}, I, p(\cdot), \alpha(\cdot), \mathcal{H}, H(\cdot), \iota(\cdot), \rho(\cdot), u \}$.
\end{definition}

\begin{comment*}
	Restrictions of this definition:
	\begin{enumerate}
		\item Finite set of actions
		\item Finite number of moves
		\item Finite number 	of players
	\end{enumerate}
\end{comment*}

\begin{definition}[Strategy]
	Let $\mathcal{H}_i$ denote the collection of player $i$'s information sets, $\mathcal{A}$ the set of possible actions in the game, and $C(H) \subset \mathcal{A}$ the set of actions possible at information set $H$. A \textbf{strategy} for player $i$ is a function $s_i \colon \mathcal{H}_i \Rightarrow \mathcal{A}$ such that $s_i(H) \in C(H)$ for all $H \in \mathcal{H}_i$.
\end{definition} 

\begin{definition}[Normal Form Representation]
	For a game with $I$ players, the \textbf{normal form representation} $\Gamma_N$ specifies for each player $i$ a set of strategies $\mathcal{S}_{i}$ (with $s_i \in \mathcal{S}_i$) and a payoff function $u_i(s_1, \dotsc, s_l)$, formally 
	$$ \Gamma_N = [I, \{ S_i \}, \{ u_i(\cdot) \}]. $$
\end{definition} 

\begin{definition} ~\
	\begin{enumerate}
		\item $s_i \colon \mathcal{H}_i \rightarrow \mathcal{A}$ describes deterministic choices at each $H \in \mathcal{H}_i$ and is called a \textbf{pure strategy}
		\item a \textbf{mixed strategy} is a probability distribution over all pure strategies $\sigma_i \colon \mathcal{S}_i \Rightarrow [0, 1]$, with $\sigma_i(s_i) \geq 0$ and $\sum_{s_i \in \mathcal{S}_i} \sigma_i(s_i) = 1$.
		\item player $i$'s set of possible mixed strategies can be associated with the points of the simplex $\Delta(\mathcal{S}_i)$, called the \textbf{mixed extension} of $\mathcal{S}_i$.
		\item since we assume that individuals are expected utility maximisers, player $i$'s utility of a profile of mixed strategies $\sigma = \left( \sigma_i, \dotsc, \sigma_l \right)$ is given by
			$$ u_i(\sigma) = \sum_{s \in \mathcal{S}} [\sigma_1(s_1) \cdot \sigma_2(s_2) \cdot \dotsc \cdot \sigma_l(s_l)] \cdot u_i(s), $$
			where $s = (s_1, \dotsc, s_l)$.
	\end{enumerate}
\end{definition}

\begin{definition}[Behaviour Strategy]
	Given an extensive form game $\Gamma_E$, a \textbf{behaviour strategy} for player $i$ specifies for every information set $h \in \mathcal{H}_i$ and action $a \in C(H)$, a probability $\lambda_i(a, H) \geq 0$, with
	$$ \sum_{a \in C(H)} \lambda_i(a, H) = 1 \text{ for all } H \in \mathcal{H}_i. $$
\end{definition}

\begin{definition}[Perfect Recall]
	A player has \textbf{perfect recall} if he doesn't \enquote{forget} what she once knew, including her own actions.
\end{definition}

\begin{theorem}
	If $\Gamma_E$ is an extensive form game with perfect recall, then for any mixed strategy there is an outcome equivalent behaviour strategy and vice versa.	
\end{theorem}

\section{Rationalisable Strategies}

Central question of Game Theory: What should we expect to observe in a game played by rational players? Or more precisely: What should we expect to observe in a game played by rational players who are fully knowledgeable about the structure of the game and each others' rationality? ~\\

We first address the above question for simultaneous-move games, which we study using their normal form representation. We use the following notation:
\begin{itemize}
	\item $\Gamma_N = [I, \{ S_i \}, \{ u_i(\cdot)]$ if we consider pure strategies only, ~\\
		$\Gamma_{N} = [I, \{ \Delta(S_i)\}, \{ u_i(\cdot) \}]$ if we allow for mixed strategies
	\item $s_{-i} = (s_1, \dotsc, s_{i-1}, s_{i+1}, \dotsc, s_l) \in \mathcal{S}_{-i}$ where $\mathcal{S}_{-i} = S_1 \times \dotsc \times S_{i-1} \times S_{i+1} \times \cdots \times S_{l}$
	\item $s = (s_i, s_{-i})$
\end{itemize}

\begin{definition}[Strictly Dominant Strategy]
	A strategy $s_i \in \mathcal{S}_i$ is \textbf{strictly dominant} for player $i$ in game $\Gamma_N = ]I, \{  \mathcal{S}_i \}, \{ u_i(\cdot)\}]$ if for all $s_i' \neq s_i$:
	$$ u_{i}(s_i, s_{-i}) > u_i(s_i', s_{-i})  $$
	for all $s_{i} \in \mathcal{S}_{-i}$.
\end{definition}
Applied to Prisoner's Dilemma: Confess is a strictly dominant strategy for each player.

\begin{definition}[Strictly Dominated Strategy]
	$s_i \in \mathcal{S}_i$ is \textbf{strictly dominated} for player $i$ in game $\Gamma_N$ if there exists another strategy $s_i' \in \mathcal{S}_i$ such that:
	$$ u_i(s_i', s_{-i}) \geq u_i(s_i, s_{-i}) $$
	for all $s_{-i} \in \mathcal{S}_{-i}$. In this case we say that $s_i'$ strictly dominates $s_i$.
\end{definition}

\begin{definition}[Weakly Dominated Strategy]
	$s_i \in \mathcal{S}_{i}$ is \textbf{weakly dominated} for player $i$ in game $\Gamma_N$ if there exists another strategy $s_i' \in \mathcal{S}_i$ such that:
	$$ u_i(s_i', s_{-i}) \geq u_i(s_i, s_{-i}) $$
	for all $s_{-i} \in \mathcal{S}_{-i}$, with strict inequality for at least one $s_{-i}$.
\end{definition}

In this game, the iterated elimination of strictly dominated strategies still leads to a unique prediction. In general, the order of elimination of strictly dominated strategies does not matter! How about iterated elimination of weakly dominated strategies?

\begin{definition}
	A strategy $\sigma_i \in \Delta(\mathcal{S}_i)$ is strictly dominated for $i$ in game $\Gamma_{N} = [I, \{ \Delta(\mathcal{S}_i)\}, \{ u_i(\cdot) \}]$ if there exists another strategy $\sigma_i' \in \Delta(\mathcal{S}_i)$ such that for all $\sigma_{-i} \in \Pi_{j \neq i} \Delta(\mathcal{S}_{j})$:
	$$ u_{i}(\sigma_i', \sigma_{-i}) > u_i(\sigma_i, \sigma_{-i}). $$
\end{definition}


\begin{proposition}
	Player $i$'s pure strategy $s_i \in \mathcal{S}_i$ is strictly dominated in a game $\Gamma_N = [I, \{ \Delta(\mathcal{S}_i)\}, \{ u_i(\cdot)\}]$ if and only if there exists another strategy $\sigma_i' \in \Delta(\mathcal{S}_i)$ such that
	$$ u_i(\sigma_i', s_{-i}) > u_i(s_i, s_{-i}) \text{ for all } s_{-i} \in \mathcal{S}_{-i}. $$
	
	\begin{proof}
		This follows because we can write
		$$ u_i(\sigma_i', \sigma_{-i}) - u_i(s_i, \sigma_{-i}) = \sum_{s_{-i} \in \mathcal{S}_{-i}} \left[ \Pi_{k \neq i} \sigma_{k}(s_{k}) \right] \left[ u_{i}(\sigma_i', s_{-i}) - u_{i}(s_i, s_{-i}) \right]. $$
		And this expression is positive for all $\sigma_{-i}$ if and only if $u_i(\sigma_i', s_{-i}) - u_{i}(s_{i}, s_{-i})$ is positive for all $s_{-i}$.
	\end{proof}
\end{proposition}

\begin{definition}[Best response]
	The strategy $\sigma_i$ is a \textbf{best response} for player $i$ to her rivals' strategies $\sigma_{-i}$ if:
	$$ u_i(\sigma_i, \sigma_{-i}) \geq u_i(\sigma_i', \sigma_{-i}) $$
	for all $\sigma_i' \in \Delta(\mathcal{S}_i)$. Strategy $\sigma_i$ is never a best response if there is no $\sigma_{-i}$ for which $\sigma_{i}$ is a best response.
\end{definition}

\begin{definition}[Rationalisable Strategies]
	In game $\Gamma_N = [I, \{ \Delta(\mathcal{S}_i) \}, \{ u_i(\cdot) \}]$, the strategies in $\Delta(\mathcal{S}_i)$ that survive the iterated elimination of strategies that are never a best response are known as player $i$'s \textbf{rationalisable strategies}.
\end{definition}

\section{Nash Equilibrium}

\begin{definition}[Nash Equilibrium]
	A strategy profile $s = (s_1, \dotsc, s_l)$ constitutes a Nash equilibrium (NE) of game $\Gamma_N$ if for every $i = 1, \dotsc, l$
	$$ u_i(s_i, s_{-i}) \geq u_i(s_i', s_{-i}) \text{ for all } s_i' \in \mathcal{S}_i $$
	In the game on the previous slide, there is only one Nash equilibrium.
\end{definition}

Why should we acre about Nash equilibria? Why should players' conjecture about each other's play be correct?
\begin{enumerate}
	\item If there is a unique predict outcome to a game, it must be a Nash-Equilibrium.
	\item Thus, a \enquote{focal point} (see example part 2) can be the unique predicted outcome to a game only if it is a Nash-Equilibrium.
	\item An agreement between players is self-enforcing if it is a Nash-Equilibrium.
	\item In a repeated game, a social convention to play the game might emerge. Only a Nash-Equilibrium can be maintained as a stable convention.
\end{enumerate} 
 
\begin{definition}[Mixed Strategy Nash Equilibrium]
	A mixed strategy profile $\sigma = (\sigma_1, \dotsc, \sigma_l)$ constitutes a Nash equilibrium of game $\Gamma_N$ if for every $i=1, \dotsc, l$,
	$$ u_i(\sigma_i, \sigma_{-i}) \geq u_i(\sigma_i', \sigma_{-i}) \text{ for all } \sigma_i' \in \Delta(\mathcal{S}_i). $$
\end{definition} 
 
\begin{proposition} 
	Let $\mathcal{S}_{i}^{+} \subset \mathcal{S}$ denote the set of pure strategies that player $i$ plays with positive probability in mixed strategy profile $\sigma = (\sigma_1, \dotsc, \sigma_l)$. Strategy profile $\sigma$ is a Nash equilibrium in game $\Gamma_N$ if and only if for all $i = 1, \dotsc, l$,
	\begin{enumerate}
		\item $u_i(s_i, \sigma_{-i}) = u_i(s_i', \sigma_{-i})$ for all $s_i, s_i' \in \mathcal{S}_i^+$
		\item $u_i(s_i, \sigma_{-i}) \geq u_i(s_i', \sigma_{-i})$ for all $s_i \in \mathcal{S}_i^+$ and all $s_i' \notin \mathcal{S}_i^+$.
	\end{enumerate}
\end{proposition} 
 
\begin{itemize}
	\item In a Nash equilibrium each player's strategy is a best response to all other players' strategies.
	\item Let $b_i(s_{-i})$ denote the best response(s) of player $i$ to the strategies $s_{-i}$
	\item Then $b_i \colon \mathcal{S}_{-i} \Rightarrow \mathcal{S}_i$ is a correspondence, called player $i$'s best response correspondence.
	\item Define $b \colon \mathcal{S} \Rightarrow \mathcal{S}$ by $(s_1, \dotsc, s_l) \Rightarrow b_1(s_{-1}) \times \dotsc \times b_l(s_{-l})$
	\item A strategy profile $s \in \mathcal{S}$ is a Nash equilibrium if and only if $s \in b(s)$
	\item Thus, to prove existence of Nash equilibria, we have to show that a fixed point of the correspondence $b$ exists
	\item To do so, we employ Kakutani's fixed-point theorem
\end{itemize} 
 
\begin{lemma}
	If $\mathcal{S}_1, \dotsc, \mathcal{S}_l$ are nonempty, compact and convex and $u_i$ is continuous in $\mathcal{S}_1, \dotsc, \mathcal{S}_l$ and quasi-concave, then player $i's$ best response correspondence $b_i(\cdot)$ is nonempty-valued, convex-valued and upper hemicontinuous.
\end{lemma} 
 
\begin{definition}[Quasi-Concave Function]
	The function $f \colon A \Rightarrow \mathbb{R}$, defined on the convex set $A \subset \mathbb{R}^N$, is quasi-concave if its upper contour sets $\{ x \in A \colon f(x) \geq t \}$ are convex sets.
\end{definition} 
 
\begin{definition}[Upper Hemicontinuous Correspondence]
	Given $A \subset \mathbb{R}^{N}$ and the closed set $Y \subset \mathbb{R}^{K}$, the correspondence $f \colon A \Rightarrow Y$ is upper hemicontinuous if it has a closed graph and the images of compact sets are bounded.
\end{definition} 

\begin{theorem}[Kakutani's Fixed Point Theorem]
	Suppose that $A \subset \mathbb{R}^N$ is a nonempty, compact, convex set, and that $f \colon A \Rightarrow A$ is a correspondence from $A$ into itself that is nonempty-valued, convex-valued and upper hemicontinuous. ~\\
	
	Then $f(\cdot)$ has a fixed point; that is, there is an $x \in A$ such that $x \in f(x)$.
\end{theorem}
 
\begin{proposition}
	A Nash equilibrium exists in game $\gamma_N$ if for all $i = 1, \dotsc, l$,
	\begin{enumerate}
		\item $\mathcal{S}_i$ is a nonempty, convex, and compact subset of some Euclidean space $\mathbb{R}^M$
		\item $u_i(s_1, \dotsc, s_l)$ is continuous in $(s_1, \dotsc, s_l)$ and quasi-concave in $s_i$.
	\end{enumerate}
	
	\begin{proof}
		By the lemma about strategy sets, $b(\cdot)$ is nonempty, convex-valued and upper hemicontinuous. By Kakutani's fixed point theorem there exists an $s \in \mathcal{S}$ such that $s \in b(s)$. By the definition of $b$: $s_i \in b_i(s_{-i})$ for all $i = 1, \dotsc, l$. Thus $s$ is a Nash equilibrium.
	\end{proof}
\end{proposition} 

\begin{proposition}
	Every Game $\Gamma_N = \left[ I, \{ \Delta(\mathcal{S}_i) \}, \{u_i(\cdot)\} \right]$ in which the sets $\mathcal{S}_1, \dotsc, \mathcal{S}_l$ have a finite number of elements has a mixed strategy Nash equilibrium.
\end{proposition}

This follows from the previous proposition on the existence of Nash equilibria because the set of mixed strategies $\Delta(\mathcal{S}_i)$ of a finite number if pure strategies is nonempty, convex, and compact.
 
\section{Subgame Perfection in Dynamic Games}

\begin{proposition}[Principle of sequential rationality]
	A strategy should specify optimal actions at every point in the game tree given the opponents’ strategies.
\end{proposition}

\begin{proposition}[Backward induction]
	Backward induction is an iterative procedure to identify Nash equilibria that satisfy the principle of sequential rationality in dynamic games:
	\begin{itemize}
		\item Determine the optimal actions at the final decision nodes in the tree.
		\item Derive the reduced extensive form game by deleting the part of the game following these decision nodes and replacing them by the payoffs that result from the optimal play.
		\item Proceed to the next-to-last decision nodes and solve for the optimal actions to be taken there by players who correctly anticipate the actions that will follow at the final nodes.
		\item Continue in this way backwards through the game tree.
	\end{itemize}
\end{proposition}

\begin{theorem}[Zermelo’s Theorem]Every finite game of perfect information $\Gamma_E$ has a pure strategy Nash equilibrium that can be derived through backward induction. Moreover, if no player has the same payoffs at any two terminal nodes, then there is a unique Nash equilibrium that can be derived in this manner.
\end{theorem}

\begin{definition}[Subgame]
	A subgame of an extensive form game $\Gamma_E$ is a subset of the game having the following properties:
	\begin{enumerate}
		\item It begins with an information set containing a single decision node, contains all the decision nodes that are successors of this node, and contains only these nodes.
		\item If decision node x is in the subgame, then every $x' \in H(x)$ is also, where $H(x)$ is the information set that contains decision node $x$.
	\end{enumerate}
\end{definition} 

\begin{definition}[Subgame Perfect Nash Equilibrium]
	A profile of strategies $\sigma = (\sigma_1, \dotsc, \sigma_l)$ in an $l$-player extensive form game $\Gamma_E$ is a subgame perfect Nash equilibrium (SPNE) if it induces a Nash equilibrium in every subgame of $\Gamma_E$.	
\end{definition}

\begin{proposition}
	Consider an extensive form game $\Gamma_E$ and some subgame $G$ of $\Gamma_E$. Suppose that strategy profile $\gamma^G$ is a SPNE in subgame $G$, and let $\Gamma_E$ be the reduced game formed by replacing subgame $G$ by a terminal node with payoffs equal to those arising from play of $\sigma^G$. Then:
	\begin{enumerate}
		\item In any SPNE $\sigma$ of $\sigma_E$ in which $\sigma^G$ is the play in subgame $G$, players’ moves at information sets outside subgame $G$ must constitute a SPNE of reduced game $\Gamma_E'$.
		\item If $\sigma'$ is a SPNE of $\Gamma_E'$, then the strategy profile $\sigma$ specifies the moves in $\sigma^G$ information sets in subgame $G$ and that specifies the moves in $\sigma'$ at information sets not in $G$ is a SPNE of $\Gamma_E$.
	\end{enumerate}
\end{proposition}

Now consider the bilateral bargaining gam with infinite horizon:

\begin{proposition}[Shaked \& Sutton (1984)]
	The infinite horizon bargaining game has a unique SPNE in which the players reach an agreement in period 1 such that player 1 earns $\frac{v}{1 + \delta}$ and player 2 $\frac{\delta v}{1 + \delta}$.
	
	\begin{proof}
		Let $\overline{v_1}$ be the largest payoff that player 1 gets in any SPNE. Then player 1's payoff in any SPNE cannot be lower than $\underline{v_1} = v - \delta \overline{v_1}$. Also $overline{v_1} \leq v - \delta \underline{v_1}$ because player 2 rejects any offer of less than $\delta \underline{v_1}$. And we have:
		$$ \overline{v_1} \leq v - \delta \underline{v_1} = \underline{v_1} + \delta \overline{v_1} - \delta \underline{v_1} \iff \overline{v_1} (1 - \delta) \leq \underline{v_1} (1 - \delta). $$
		Which implies $\overline{v_1} = \underline{v_1}$, so player 1's SPNE is uniquely determined:
		$$ \Rightarrow v_1^0 = v - \delta v_1^0 = \frac{v}{1 + \delta} \text{ and } v_2^0 = \frac{\delta v}{1 + \delta} $$ 
	\end{proof}
\end{proposition}


\chapter{Kooperative Spiele} 


Im Kontrast zur nicht-kooperativen Spieltheorie, die sich mit Spielern die individuell Entscheidungen treffen und ihre individuelle Auszahlung ohne Absprache maximieren, beschäftigt, gibt es die kooperative Spieltheorie, mit der wir uns im folgenden beschäftigen. In der kooperativen Spieltheorie können sich die Spieler gemeinsam auf Ergebnis einigen, die dann auch verpflichtend sind. Man braucht dazu Kontrollinstanzen; Wir suchen nach Stabilität und Ergebnissen, die sich in solchen Situationen ergeben.

\subsection*{Koalitionsspiele (Spiele in charakteristischer Form)}
\begin{itemize}
	\item Die Modellierung als Koalitionsspiel wird angewendet, wenn bindende Absprachen möglich sind. 
	\item Im Fokus: Was kann eine Gruppe von Spielern (eine \textit{Koalition}) gemeinsam erreichen? 
	\item Es wird dabei nicht betrachtet, wie die Koalition dies erreicht, d.h. wie sie ihre gemeinsamen Aktionen abstimmt. 
	\item Fragen: Wie wird sie dies aufteilen? Wie sollte sie dies aufteilen? Gibt es stabile Aufteilungen? 
	\item \textit{Lösung eines Koalitionsspiels}: (Menge an) Payoffvektoren mit bestimmten Eigenschaften.
\end{itemize}

Wir betrachten nur Koalitionsspiele mit transferierbarem Nutzen, also Spiele bei denen der Wert, den eine Koalition erreichen kann, beliebig unter den Mitgliedern aufgeteilt werden kann.

\begin{definition}[Koalitionsspiel mit transferierbarem Nutzen]
	Ein Koalitionsspiel $(N, v)$ mit tranferierbarem nutzen besteht aus
	\begin{itemize}
		\item einer endlichen Menge $N = \{1, \dotsc, n\}$ an Spielern und
		\item einer charakteristischen Funktion $v \colon \mathcal{P}(N) \rightarrow \mathbb{R}$, die jeder Teilmenge $S$ von $N$ einen (Koalitions-) Wert $v(\mathcal{S})$ zuweist.
	\end{itemize}
	($\mathcal{P}(N)$ ist die Potenzmenge von $N$.)
\end{definition} 

\begin{bemerkung} ~\
  \begin{itemize}
	\item Die charakteristische Funktion wird auch Koalitionsfunktion genannt.
	\item Wir treffen die Annahme, dass Aktionen von Spielern in $N \setminus S$ den Wert $v(S)$ nicht beeinflussen (vgl. \enquote{outside option}).
	\item Wir interpretieren $v(S)$ als den Payoff, den sich die Koalition $S$ aus eigener Kraft sichern kann.
	\item Es gelte $v(\emptyset) = 0$.
	\item Die Spieler in S entscheiden über mögliche Aufteilungen von $v(S)$ auf die Spieler in $S$ (da der Nutzen transferierbar ist).	
  \end{itemize}	
\end{bemerkung}

Stille Annahme: Existenz einer übergeordneten Kontrollinstanz.~\\

Zur Vereinfachung betrachten wir im Folgenden superadditive Spiele: Eine Koalition $S \cup T$ kann immer mindestens das erreichen, was ihre disjunkten Teilkoalitionen $S$ und $T$ getrennt erreichen können.

\begin{definition}[Superadditive Spiele]
	Ein Koalitionsspiel $(N, v)$ ist superadditiv, wenn
	$$ v(S \cup T) \geq v(s) + v(t) $$
	für alle Koalitionen $S$ und $T$ mit $S \cap T = \emptyset$.
\end{definition}
	
Bei der Analyse von Koalitionsspielen spielt der Payoff, den die einzelnen Spieler erhalten, eine Rolle.
\begin{itemize}
	\item Ein Payoffvektor sei bezeichnet mit $x = (x_1, \dotsc, x_n)$.
	\item Der Gesamtpayoff, den die Spieler einer Gruppe $S$ erhalten ist also $\sum_{i \in S} x_i$.
	\item Anmerkung: Hier betrachten wir einen Payoffvektor und berechnen, wie hoch der gemeinsame Payoff der Spieler in $S$ ist. Dies hat nichts mit $v(S)$ zu tun, dem Payoff, den die Koalition $S$ aus eigener Kraft erreichen kann.
\end{itemize} 

\begin{definition}[Zulässiger Payoffvektor]
	In einem superadditiven Spiel ist ein Payoffvektor $x$ zulässig, wenn
	$$ \sum_{i \in N} x_i \leq v(N) $$
\end{definition} ~\\
	
Wir werden zwei Lösungskonzepte kennen lernen:\begin{itemize}
	\item Ein Mengenkonzept, das eine Menge von Payoffvektoren als Lösung vorschlägt: der Kern.	\item Ein Wertkonzept, das eine eindeutige Lösung des Spiels vorschlägt: der Shapley-Wert.
\end{itemize}

\section{Der Kern} 

\begin{itemize}
	\item Der Kern enthält alle \enquote{stabilen} Payoffvektoren.
	\item Idee: Ein Payoffvektor eines Koalitionsspiels ist stabil, wenn es keine Koalition gibt, die aus eigener Kraft für jedes ihrer Mitglieder einen höheren Payoff erzielen könnte.
	\item Bei transferierbarem Nutzen: Ein Payoffvektor ist stabil, wenn es keine Koalition gibt, deren Wert höher ist als die Summe der Payoffs ihrer Mitglieder (im betrachteten Payoffvektor).
	\item Da wir nur superadditive Spiele betrachten, wird immer die große Koalition den Gesamtpayoff der Kernlösung (falls diese existiert) bestimmen.
	\item Der Kern kann aus mehreren Payoffvektoren bestehen, er kann eindeutig sein und er kann leer sein.
\end{itemize}

\begin{definition}[Kern]
	Der Kern eines Koalitionsspiels mit transferierbarem Nutzen $(N, v)$ ist die Menge zulässiger Payoffvektoren $x$, für die gilt
	$$ \sum_{i \in S} x_i \geq v(S) $$
	für alle $S \subseteq N$.
\end{definition}

\textbf{Eigenschaften:}
\begin{itemize}
	\item Das bedeutet, dass keine Koalition einen Payoffvektor im Kern blockieren kann: $\exists! S \subseteq N$, so dass $v(S) > \sum_{i \in S} x_i$.
	\item Payoffvektoren im Kern sind individuell rational: $x_i \geq v(i)$.
	\item Da der Kern eine Menge an Payoffvektoren ist, welche Lösung eines Systems linearer Ungleichungen sind, ist er eine abgeschlossene und konvexe Menge.
\end{itemize}

\begin{unnamedtheorem}[Bedeutung des Kerns] ~\
	\begin{enumerate}
		\item Ein Payoffvektor, der nicht im Kern liegt, ist als Lösung instabil: Mindestens eine Koalition wird der Absprache nicht zustimmen.
		\item Wenn der Kern leer ist, gibt es keine Aufteilung des Gesamtwerts der großen Koalition (in superadditiven Spielen), welcher alle Gruppen zustimmen würden. Damit sind die Voraussetzungen für eine Aufteilung der Payoffs schlecht. Zum Beispiel kann dies bei der Gewinn- oder Kostenaufteilung in Unternehmen oder in Wertschöpfungsketten eine Rolle spielen.
	\end{enumerate} 
\end{unnamedtheorem}

\section{Der Shapley-Wert}

\begin{itemize}
	\item Im Gegensatz zum Kern ist der Shapley-Wert ein Wertkonzept, d.h. eine Lösungsfunktion, die genau einen Payoffvektor als Lösung auswählt.
	\item Er schlägt eine Aufteilung des gemeinschaftlich erreichten Werts vor, die in gewissem Sinne \enquote{fair} ist. Er kann in vielen Spielen auch als Machtindex interpretiert werden.
	\item Die Idee hinter dem Shapley-Wert ist, dass jeder Spieler den Durchschnitt seiner marginalen Beiträge zum Wert aller möglichen Koalitionen bekommt.
	\item Der Shapley-Wert kann auch axiomatisch begründet werden.
\end{itemize}

\begin{definition}[Shapely-Wert]
	Der Shapley-Wert $\phi(N, v) = \left( \phi_1(N,v), \dotsc, \phi_n(N,v) \right)$ im Koalitionsspiel $(N, v)$ ist gegeben durch
	$$ \phi_i(N,v) = \frac{1}{n!} \sum_{\pi \in \pi_N} \left( v\left(S_i(\pi) \cup \{ i \} \right) - v\left(S_i(\pi)\right) \right) $$
	für alle $i \in N$.
\end{definition}

\begin{itemize}
	\item $\pi_N$ ist die Menge aller möglichen Spielerreihenfolgen. Es gibt $n!$ Reihenfolgen.
	\item $S_i(\pi)$: Menge an Spielern, die in der Reihenfolge $\pi$ vor $i$ kommen.
	\item Alternative Darstellung:
		$$ \phi_i(N,v) = \sum_{S \subseteq N \setminus \{ i \}}\frac{\left( n - |S| - 1 \right)!\left(|S|\right)!}{n!} \left( v\left( S \cup \{i\} \right) v(S) \right). $$
\end{itemize}

\textbf{Intuition} ~\\Wenn die Koalition durch sequentielles Eintreten der Spieler gebildet wird und jeder Spieler seinen Beitrag $v(S \cup \{ i \}) - v(S)$ zur bisherigen Koalition $S$ als faire Entschädigung verlangt, dann entspricht $\phi_i(N, V)$ diesem Wert, wenn man den Durchschnitt über alle möglichen Reihenfolgen betrachtet, gemä{\ss} derer die Koalition $N$ sich bilden kann. ~\\

Es kann gezeigt werden, dass der Shapley-Wert $\phi(N, v)$ der einzigen Lösung $\varphi(N, v)$ entspricht, die folgenden vier Axiome für alle $(N, v)$ erfüllt.

\begin{unnamedtheorem}[Axiomatische Begründung] ~\
	\begin{enumerate}
		\item[A1] Effizienz: $\sum_{i \in N} \varphi_i(N,v) = v(N)$ ~\\
			\textit{Dieses Axion verlangt, dass keine möglichen Nutzen verloren gehen. Alles was die große Koalition erreicht, wird aufgeteilt.}
		\item[A2] Symmetrie: Wenn für zwei Spieler $i$ und $j$ gilt, dass
			$$ v\left( S \cup \{i\} \right) - v(S) = v\left( S \cup \{j\} \right) - v(S) $$
			für alle $S$ in denen $i$ und $j$ nicht enthalten sind, dann gilt $\varphi_i(N,v) = \varphi_j(N,v)$. ~\\
			\textit{Dieses Axiom verlangt, dass eine Lösung nicht von der Bezeichnung der Spieler abhängt. Wenn Spieler austauschbar sind (da sie zu jeder Koalition dasselbe beitragen) dann soll auch ihr Wert der selbe sein.}
		\item[A3] Null-Spieler: Wenn für einen Spieler $i$ gilt, dass
			$$ v\left( S \cup \{i\} \right) - v(S) = 0 $$
			für alle $S$, dann gilt $\varphi_i(N, v) = 0$. ~\\
			\textit{Wenn ein Spieler zu keiner Koalition etwas beiträgt, soll er auch nichts erhalten.}	
		\item[A4] Additivität: Ein Wert $\varphi$ erfüllt Additivität, wenn für jedes Paar von Spielen $(v, N)$ und $(w, N)$ gilt
			$$ \varphi_i(v + w, N) = \varphi_i(v, N) + \varphi_i(w, N) $$
			für alle $i \in N$, wobei $(v + w, N)$ definiert sei durch $(v + w)(S) = v(S) + w(S)$ für alle $S \subseteq N$.
			\textit{Wenn die Koalitionswerte zweier Spiele jeweils addiert ein anderes Spiel ergeben, dann soll auch der Wert jedes Spielers die Summe seiner Werte in den beiden Spielen sein.}
	\end{enumerate}
\end{unnamedtheorem}

\begin{satz}
	Der Shapley-Wert $\phi(N, v)$ ist der einzige wert, der A1-A4 erfüllt.
\end{satz}

\section{Einfache Spiele} 

\begin{definition}[Einfaches Spiel]
	Ein Koalitionsspiel $(N, v)$ hei{\ss}t einfach, wenn für jede Koalition $S \subseteq N$ entweder $v(S) = 0$ und $v(S) = 1$ gilt.
\end{definition}

\begin{itemize}
	\item Eine Koalition $S$ für die $v(S) = 1$ gilt hei{\ss}t Gewinnerkoalition.
	\item Ein Spieler, der in jeder Gewinnerkoalition des Spiels ist, hei{\ss}t Veto-Spieler.
\end{itemize} 

\begin{satz} ~\
	\begin{itemize}
		\item Wenn es in einem einfachen Spiel keinen Veto-Spieler gibt, ist der Kern leer.
		\item Wenn es in einem einfachen Spiel (einen oder mehrere) Veto-Spieler gibt, besteht der Kern aus allen nicht-negativen zulässigen Payoffvektoren, in denen die anderen (Nicht-Veto-)Spieler Null erhalten.
	\end{itemize}
\end{satz}

\section{Konvexe Spiele} 

Gibt es eine Charakterisierung von Spielen, für die der Shapley-Wert im Kern liegt?

\begin{definition}[Konvexes Spiel]
	Ein Spiel heißt konvex, wenn für jeden Spieler $i$ der marginale Beitrag von $i$ grö{\ss}er ist wenn die Koalition wächst; genauer, wenn für alle $S \subset T$ und $i \in N \setminus T$ gilt, dass
	$$ v( S \cup \{i\}) - v(S) \leq v( T \cup \{ i \}) - v(T). $$
\end{definition}

\begin{satz}
	Der Shapley-Wert eines konvexen Spiels liegt im Kern.
\end{satz}
Aus diesem Satz folgt direkt, dass der Kern eines konvexen Spiels nicht leer ist.


\chapter{Evolutionäre Spieltheorie}

  
\section{Spiele in Normalform}
Für symmetrische Spiele:
$$ A = \left( a_{ij} \right) \quad i = 1, \dotsc, m_{i}, ~ j = 1, \dotsc, m_{j} $$
d.h.
% todo game table 
\begin{description}
	\item $N$: Spielermenge $|N| = n$
	\item $\Sigma_{i}$: Menge der reinen Strategien von $i \in N$, $\left| \Sigma_{i} \right| = m_{i}$, $\sigma_{i} \in \mathcal{E}_{i}$.
	\item $S_{i}$: Menge der gemischten Strategien von $i \in N$
		\begin{description}
			\item $S_{i} = \left\{ \right\}$.
			\item $s_{ij} = \mathds{P}(\sigma_{ij})$.
		\end{description}
\end{description}
  
\begin{definition}[Trägermenge] Wir definieren die Trägermenge für jeden Spieler $i \in N$:
	$$ C(S_{i}) = \left\{ \sigma_{ij} \in \Sigma_{i} : s_{ij} > 0 \right\}, $$
	als die Menge der Strategien die mit positiver Wahrscheinlichkeit gespielt werden.
\end{definition}  

\begin{definition}[Beste-Antwort-Menge] Sei
	$$ B_{i}(s_{-i}) = \left\{ \sigma_{j} \in \Sigma_{i} : H(\sigma_{ij}, s_{-i}) = \max_{\sigma_{ik \in \Sigma_{i}}} H(\sigma_{ik}, s_{-i}) \right\} $$ 
	$H$ bezeichne pay-off-Funktion ~\\
	$$ \hat{H}(s_{-i}) \coloneqq \max_{\sigma_{il} \in \Sigma_{i}} H(\sigma_{ik}, s_{-i}) $$
\end{definition}


\begin{unnamedtheorem}[Grundannahmen der evolutionären Spieltheorie]
	\begin{enumerate}
		\item große Population
		\item Population ist monomorph
		\item random matching
		\item Wettstreit (Spiel) ist statisch und symmetrisch
			$$ \Rightarrow \text{ symmetrisches Spiel in Normalform mit zwei Spielern}. $$
		\item Auszahlung entspricht der \enquote{biologischen Fitness} ($\phi$ Anzahl Nachkommen)
		\item Reproduktion ist asexuell und die von den Eltern gewählt Strategie wird unverändert an die Nachkommen vererbt (nur Selektion, keine Mutation).
	\end{enumerate}
\end{unnamedtheorem} 
 

\begin{unnamedtheorem}[Symmetrisches 2-Personenspiel in Normalform]
	Spieler müssen nicht unterschieden werden $\Rightarrow$ Strategieraum:
	$$ S = \{ s\in \R^{m} : \sum_{i=1}^{m} s_{i} = 1, s_{i} \geq 0, i = 1, \dotsc, m \} $$
\end{unnamedtheorem}
  
 
\begin{definition}[Evolutionär stabile Strategie, ESS]
	Eine Strategie $p \in S$ hei{\ss}t evolutionär stabil, wenn
	\begin{enumerate}
		\item $H(p,p) \geq H(q, p)$ für alle $q \in S$ (Gleichgewichtsbedingung)
		\item Für alle $q \in S \setminus \{ p \}$ mit $H(q, p) = H(p, p)$ gilt: $H(p, q) > H(q, q)$ (Stabilitätsbedingung)
	\end{enumerate}
\end{definition}  


\begin{unnamedtheorem}[Eigenschaften von evolutionär stabilen Strategien] ~\
	\begin{itemize}
		\item Ist $p \in S$ eine evolutionär stabile Strategie, dann bildet $(p, p)$ ein symmetrisches Nash-Gleichgewicht
		\item Jede $2 \times 2$-Matrix $A = \begin{pmatrix}
			a_{11} & a_{12} \\ a_{21} & a_{22}
		\end{pmatrix}$ mit $H(p,p) = p'Ap$ sodass $a_{11} \neq a_{21}$ und / oder $a_{12} = a_{22}$, besitzt eine ESS
		Ist $(p,p)$ ein striktes NGG, dann ist $p$ eine ESS. Im strikten NGG $(p, p)$ gilt $C(p) = B(p)$. Ein striktes NGG ist immer ein Gleichgewicht in reinen Strategien. Beispiel:
   \begin{game}{2}{2}[~][]
   	    &  ~      &  ~     \\
   	 ~  &    $3, 3$      & $2, 0$  \\
   	  	&  $0, 2$ & $4, 4$\\
   \end{game}
	\item Im Normalformspielen mit $m \times m$-Matrizen $a$ mit $m \geq 3$ existieren entweder endlich viele ESS keine.
	\end{itemize}
\end{unnamedtheorem}
  
\begin{unnamedtheorem}[Allgemein gilt]
	Ist $p$ ESS $\Rightarrow \neg \exists \sigma \in C(p)$ mit $\sigma \in C(S^{*})$ für $s^{*} \neq q$ ist Nash-Gleichgewicht
\end{unnamedtheorem} 

$\Rightarrow \#$ ESS $\leq \left| \Sigma \right|$ - Gleichheit nur, fall es kein ESS in gemischten Strategien gibt.  

\printindex

\end{document}